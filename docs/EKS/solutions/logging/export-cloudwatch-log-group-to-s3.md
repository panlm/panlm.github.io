---
title: export-cloudwatch-log-group-to-s3
description: å¯¼å‡º cloudwatch æ—¥å¿—åˆ° s3
created: 2022-08-17 21:19:15.620
last_modified: 2023-12-31
tags:
  - aws/mgmt/cloudwatch
  - aws/storage/s3
  - myblogs
---
> [!WARNING] This is a github note

# export-cloudwatch-log-group-to-s3

- https://docs.aws.amazon.com/zh_cn/AmazonCloudWatch/latest/logs/S3ExportTasks.html#S3Permissions

- å¯¼å‡ºæ—¥å¿—æ ¼å¼æ–‡ä»¶ç±»ä¼¼ï¼š
![](../../../git-attachment/export-cloudwatch-log-group-to-s3-1.png)

## create bucket and policy
```sh
bucket_name=my-exported-logs-2358-$RANDOM
aws_region=us-east-2
envsubst >policy.json <<-EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "s3:GetBucketAcl",
            "Effect": "Allow",
            "Resource": "arn:aws:s3:::${bucket_name}",
            "Principal": { "Service": "logs.${aws_region}.amazonaws.com" }
        },
        {
            "Action": "s3:PutObject" ,
            "Effect": "Allow",
            "Resource": "arn:aws:s3:::${bucket_name}/*",
            "Condition": { "StringEquals": { "s3:x-amz-acl": "bucket-owner-full-control" } },
            "Principal": { "Service": "logs.${aws_region}.amazonaws.com" }
        }
    ]
}
EOF

aws s3api create-bucket --bucket ${bucket_name} \
--create-bucket-configuration LocationConstraint=${aws_region} \
--region ${aws_region}

# will overwrite existed policy attached on s3 bucket !
aws s3api put-bucket-policy --bucket ${bucket_name} --policy file://policy.json

```

## export task
```sh
loggroup_name="/aws/eks/ekscluster1/cluster"
begin_time=$(date --date "2 days ago" +%s)
end_time=$(date --date "1 days ago" +%s)

suffix=$(date +%Y%m%d-%H%M%S)
#for i in kube-apiserver-audit kube-apiserver kube-scheduler authenticator kube-controller-manager cloud-controller-manager ; do
for i in kube-apiserver-audit ; do
  task_name=${i}-${suffix}
  # create export task
  aws logs create-export-task --task-name ${task_name} \
    --log-group-name ${loggroup_name} \
    --log-stream-name-prefix ${i} \
    --from ${begin_time}000 --to ${end_time}000 \
    --destination ${bucket_name} \
    --destination-prefix ${i} |tee /tmp/$$
  task_id=$(cat /tmp/$$ |jq -r '.taskId')
  while true; do
    # describe task
    aws logs describe-export-tasks \
      --task-id ${task_id} |tee /tmp/$$.task
    task_status=$(cat /tmp/$$.task |jq -r '.exportTasks[0].status.code')
    if [[ ${task_status} == "COMPLETED" ]]; then
      break
    fi
    sleep 10
  done
done

```

## remaining issues 
- éœ€è¦ä¿å­˜å¯¼å‡ºçš„æ—¶é—´ç‚¹ï¼Œä»¥ä¾¿äºŽä¸‹æ¬¡ä»Žæ”¹æ—¶é—´ç‚¹ç»§ç»­
- å¯¼å‡ºåŽå°†åœ¨æŒ‡å®šçš„ prefix ä¸­ï¼Œåˆ›å»º task id ä¸º folder ï¼ŒæŒ‰ç…§æ‰€æœ‰ log stream name ä½œä¸ºä¸‹ä¸€å±‚çš„ folder ï¼Œæ—¥å¿—æ–‡ä»¶ä¸º gz åŽ‹ç¼©æ ¼å¼
- å¯ä»¥çœç•¥ `log-stream-name-prefix` å‚æ•°ï¼Œå¯¼å‡ºæ‰€æœ‰æ—¥å¿—ï¼Œè€ƒè™‘æ—¥å¿—å¦‚ä½•è¿›è¡ŒäºŒæ¬¡å¤„ç†
- k8sæŽ§åˆ¶æ—¥å¿—åŒ…å«ç±»ä¼¼å‰ç¼€ï¼Œæ¯”å¦‚ `kube-apiserver-audit-xxx` å’Œ `kube-apiserver-xxxx` ï¼Œå¹¶ä¸”å‰è€…æ˜¯jsonæ ¼å¼æ—¥å¿—ï¼ŒåŽè€…æ˜¯è¡Œæ—¥å¿—ï¼Œå¦‚ä½•è¿›è¡ŒåŒºåˆ†å¯¼å‡ºåˆ°ä¸åŒ prefix è·¯å¾„ï¼Œæˆ–è€…å¯¼å‡ºåŽå¦‚ä½•è¿›è¡ŒäºŒæ¬¡å¤„ç†ï¼Œå‚è€ƒï¼š stream-k8s-control-panel-logs-to-s3 ([link](stream-k8s-control-panel-logs-to-s3.md) or [hugo](stream-k8s-control-panel-logs-to-s3.md))
- å¯¼å‡ºæ¶ˆæ¯æ ¼å¼é—®é¢˜å¾…è§£å†³ [[athena-sample-query#file-format-when-export-cwl-to-s3-ðŸ“š]] 


